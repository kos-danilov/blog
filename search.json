[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "MD, MSc Bioinformatics\nBioinformatician with expertise in cancer genomics and transcriptomics, coupled with a previous background in medicine."
  },
  {
    "objectID": "posts/nextflow/index.html",
    "href": "posts/nextflow/index.html",
    "title": "Nextflow for pipeline managment",
    "section": "",
    "text": "Nextflow is a workflow management system that simplifies running complex data analyses across different environments including laptops, HPC clusters and the cloud.\nBuilt on the dataflow programming model, it allows tasks to execute in parallel and ensures reproducibility and scalability."
  },
  {
    "objectID": "posts/nextflow/index.html#defenitions",
    "href": "posts/nextflow/index.html#defenitions",
    "title": "Nextflow for pipeline managment",
    "section": "Defenitions",
    "text": "Defenitions\nIn Nextflow, workflows are built from two core components: processes and channels.\n\nProcesses define individual computational tasks, each has its own script, input, and output. They are isolated and can run in parallel.\nChannels are the data connectors between processes.\nThey define how data moves through the workflow, enabling dynamic and asynchronous execution.\n\n\n\n\nChannels and processes\n\n\nChanel can be created using channel factories and modified during execution of the workdlow using operators"
  },
  {
    "objectID": "posts/nextflow/index.html#workflow",
    "href": "posts/nextflow/index.html#workflow",
    "title": "Nextflow for pipeline managment",
    "section": "Workflow",
    "text": "Workflow\nTypical *.nf file looks like this:\n#!/usr/bin/env nextflow\n\n// Parameters & Settings\nparams.reads = \"data/*.fastq\"\nparams.ref   = \"data/genome.fa\"\nparams.outdir = \"results\"\n\n// Imports & Libraries\ninclude { QC } from './modules/qc.nf'\ninclude { ALIGN } from './modules/align.nf'\ninclude { REPORT } from './modules/report.nf'\n\n// Custom Functions\ndef sample_id(path) {\n    return path.baseName.replace('.fastq', '')\n}\n\n// Processes\nprocess PROCESS_NAME{\n    // directives\n    container\n    publishDir \"${params.outdir}/qc\", mode: 'copy'\n\n    input:\n      val x\n      path y\n      tuple z\n\n    output:\n      tuple val x, path f\n    \n    script:\n      // can be a script from bin folder\n      fastqc ...\n\n}\n\n...\n\nworkflow {\n    // Channel creation\n    Channel\n    .fromPath(params.reads)\n    .map { file -&gt; tuple(sample_id(file), file) }\n    .set { reads_ch }\n\n    // workflow itself \n    qc_results = QC(reads_ch)\n    bam_files  = ALIGN(qc_results)\n    ...\n}\nIn order to run the script we need to have a specific version of the Nextflow pre-installed into enviroment. Following CLI interface can be used for running the pipeline:\nnextflow run &lt;pipeline&gt; [options] \\\n [--params-file &lt;file&gt;] \\\n [--&lt;param&gt; &lt;value&gt;] \\\n [-profile &lt;profile&gt;] \\\n [-resume] \\\n [-with-docker|-with-singularity]\nAfter execution nextflow create a lot of files in the work directory. These files can be reused using -resume option in case of repetitive executions. After some time work directory can be cleaned in a way:\nnextflow clean &lt;pipeline&gt; [options] [--work-dir &lt;dir&gt;] [-f]\n\n\n\n\n\n\nTip\n\n\n\nRead more about CLI nextflow commands here"
  },
  {
    "objectID": "posts/nextflow/index.html#comparison-with-other-pipeline-managers",
    "href": "posts/nextflow/index.html#comparison-with-other-pipeline-managers",
    "title": "Nextflow for pipeline managment",
    "section": "Comparison with other pipeline managers",
    "text": "Comparison with other pipeline managers\nOne can choose between various workflow managers:\n\n\n\n\n\n\n\n\n\nFeature\nNextflow\nSnakemake\nCWL (Common Workflow Language)\n\n\n\n\nLanguage\nGroovy\nPython\nYAML/JSON spec\n\n\nParallelism\nDataflow (tasks run when input ready)\nExplicit dependencies in rules\nDAG (tasks run according to DAG)\n\n\nReproducibility\nExcellent: containers & caching\nVery good: conda & containers\nHigh: strict spec & container support\n\n\nWhere it runs\nLocal, HPC, cloud, Kubernetes\nLocal, HPC (cloud possible)\nHPC & cloud via execution engines\n\n\nContainers\nDocker, Singularity, Podman\nDocker, Singularity\nDocker, Singularity\n\n\nEase of use\nModerate (Groovy DSL learning curve)\nEasy if you know Python\nSteeper, verbose YAML\n\n\nPortability\nVery high\nMedium\nHigh\n\n\nCommunity\nBig\nMedium\n???"
  },
  {
    "objectID": "posts/pixi_containers/index.html",
    "href": "posts/pixi_containers/index.html",
    "title": "Running reproducible analysis using pixi or containers for environment management",
    "section": "",
    "text": "Learn how to manage dependencies and share your analysis environment with others using pixi and containers."
  },
  {
    "objectID": "posts/pixi_containers/index.html#managing-environments-using-pixi",
    "href": "posts/pixi_containers/index.html#managing-environments-using-pixi",
    "title": "Running reproducible analysis using pixi or containers for environment management",
    "section": "Managing environments using pixi",
    "text": "Managing environments using pixi\nPixi is a modern, fast, and conda-compatible environment manager. It helps create isolated environments for your projects, handling dependencies across multiple programming languages. Key features include:\n\nFast package installation and environment creation\nConda-compatible, accessing the same package ecosystem\nLockfile support for reproducible environments\nSimple CLI interface with intuitive commands\nMulti-language support (Python, R, C++, etc.)\n\n\n\n\n\n\n\nTip\n\n\n\nTo get started with pixi, first install it following the installation guide.\n\n\n\nCreate a new environment\nIt is a good practice to have a separate env for every project. In order to configure a new env in the currect project directory use command:\npixi init -c conda-forge -c bioconda\nIf you want to add something (for example fastqc) to the env use:\npixi add fastqc\nYou can test it using:\npixi run fastqc --help\nor by activating env:\npixi shell\nfastqc\n\n\nAlternatives\nOf course there are several environment managers avaliable, you can check pros and cons of common ones in this table:\n\n\n\n\n\n\n\n\n\nTool\nDescription\nPros\nCons\n\n\n\n\nconda\nPackage and environment manager for many programming languages\n- Multi-language support- Large package ecosystem- Industry standard\n- Slow resolver- Heavy installation- Complex dependency handling\n\n\npixi\nFast conda-compatible environment manager\n- Fast installation- Lockfile support- Conda-compatible\n- Relatively new- Smaller community- Limited documentation\n\n\nvenv\nPython built-in virtual environment tool\n- Lightweight- Built into Python- Simple to use\n- Python-only- No dependency resolution- Basic feature set\n\n\nvirtualenv\nEnhanced virtual environment tool\n- Mature project- Good integration- Cross-platform\n- Python-only- Manual dependency management- No lockfile by default\n\n\npoetry\nModern Python dependency manager\n- Modern workflow- Good dependency resolver- Project management\n- Python-only- Learning curve- Can be slow"
  },
  {
    "objectID": "posts/pixi_containers/index.html#get-more-control-using-containers",
    "href": "posts/pixi_containers/index.html#get-more-control-using-containers",
    "title": "Running reproducible analysis using pixi or containers for environment management",
    "section": "Get more control using containers",
    "text": "Get more control using containers\nContainers offer a higher level of isolation and reproducibility by packaging not just the dependencies, but the entire runtime environment. Two popular containerization solutions are:\n\nDocker: Industry standard for containerization, suitable for development and testing\n\nCreates lightweight, portable environments\nExtensive ecosystem of pre-built images (Dockerhub)\nGreat for CI/CD pipelines\n\nSingularity/Apptainer: Designed for HPC and scientific computing (no root required)\n\nBetter security model for shared systems\nNative support for HPC workloads\nSeamless conversion from Docker containers\n\n\n\n\n\n\n\n\nTip\n\n\n\nSince we don’t have root rights on our server, we’re going to use apptainers in connection with singularity images. But this is not a problem - we still can use Docker images after conversion to singularity.\n\n\n\nSource\nThere are many ways how to get a container:\n\nPull from container registry (DockerHub)\nConvert Docker image to Singularity\nBuild from definition file\nConstruct container using Wave (Sequera)\n\n\n\nCreating the container\nWe can use the following command to create our first container:\napptainer pull &lt;name.sif&gt; &lt;link_to_container&gt;\n\n\n\n\n\n\nTip\n\n\n\nNote, it is better to use specific version in the file name.\n\n\n\n\nRun tools within a container\n\nRunning ‘from the outside’Running ‘from the inside’\n\n\nRun the command inside the container (good for pipelines):\napptainer exec &lt;name-of-container&gt; &lt;command&gt;\n\n\nRun in interactive mode (good for debugging):\napptainer shell &lt;name-of-container&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MedBioInfo Blog",
    "section": "",
    "text": "ggplot2 for advanced visalization\n\n\n\nR\n\nggplot2\n\nvisalization\n\n\n\n\n\n\n\n\n\nOct 10, 2025\n\n\nKonstantin Danilov\n\n\n\n\n\n\n\n\n\n\n\n\nStandartised nf-core pipelines\n\n\n\nnextflow\n\nnf-core\n\n\n\n\n\n\n\n\n\nOct 9, 2025\n\n\nKonstantin Danilov\n\n\n\n\n\n\n\n\n\n\n\n\nNextflow for pipeline managment\n\n\n\nnextflow\n\ncontainers\n\n\n\n\n\n\n\n\n\nOct 8, 2025\n\n\nKonstantin Danilov\n\n\n\n\n\n\n\n\n\n\n\n\nRunning reproducible analysis using pixi or containers for environment management\n\n\n\npixi\n\ncontainers\n\napptainer\n\n\n\n\n\n\n\n\n\nOct 7, 2025\n\n\nKonstantin Danilov\n\n\n\n\n\n\n\n\n\n\n\n\nHow to make a quarto blog\n\n\n\nquarto\n\n\n\n\n\n\n\n\n\nOct 6, 2025\n\n\nKonstantin Danilov\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/make_blog/index.html",
    "href": "posts/make_blog/index.html",
    "title": "How to make a quarto blog",
    "section": "",
    "text": "This post contains instruction about how to make your first post using Quarto blog."
  },
  {
    "objectID": "posts/make_blog/index.html#creating-a-new-blog",
    "href": "posts/make_blog/index.html#creating-a-new-blog",
    "title": "How to make a quarto blog",
    "section": "Creating a new blog",
    "text": "Creating a new blog\n\nOpen VSCode\nCreate a new blog project:\n\nPress Ctrl+Shift+P (Windows/Linux) or Cmd+Shift+P (Mac)\nType “Quarto: Create Project”\nSelect “Blog Project”\nChoose a directory for your blog\nEnter a title for your blog\n\nOpen the project:\n\nGo to File &gt; Open Folder\nSelect your blog directory\n\nPreview your blog:\n\nClick the “Preview” button in the top right corner of VSCode\nOr press Ctrl+Shift+P and type “Quarto: Preview”"
  },
  {
    "objectID": "posts/make_blog/index.html#adding-a-new-post",
    "href": "posts/make_blog/index.html#adding-a-new-post",
    "title": "How to make a quarto blog",
    "section": "Adding a new post",
    "text": "Adding a new post\n\nCreate a new post:\n\nRight-click on the posts folder\nSelect “New Folder”\nName it (e.g., “my-first-post”)\n\nCreate the post file:\n\nRight-click on your new folder\nSelect “New File”\nName it “index.qmd”\n\nAdd YAML header to your post:\n---\ntitle: \"My Post Title\"\nauthor: \"Your Name\"\ndate: \"2025-10-06\"\ncategories: [news, analysis]\n---\nWrite your content using markdown\nPreview changes:\n\nClick the “Preview” button in the top right corner\nOr use Command Palette (Ctrl+Shift+P / Cmd+Shift+P) and type “Quarto: Preview”"
  },
  {
    "objectID": "posts/make_blog/index.html#publishing",
    "href": "posts/make_blog/index.html#publishing",
    "title": "How to make a quarto blog",
    "section": "Publishing",
    "text": "Publishing\n\nRender your post\nDeploy to GitHub Pages or your preferred hosting service"
  },
  {
    "objectID": "posts/ggplot2/index.html",
    "href": "posts/ggplot2/index.html",
    "title": "ggplot2 for advanced visalization",
    "section": "",
    "text": "ggplot2 is the best R tool for making charts and graphs. Let’s look at a quick example to see how it works when you make adjustments.\nThe power of ggplot2 stems from the Grammar of Graphics philosophy, which allows you to build any plot by defining mappings and adding visual components layer by layer. This approach ensures high reproducibility and customization by giving you explicit control over every element. The primary layers of control are:"
  },
  {
    "objectID": "posts/ggplot2/index.html#economist-scatterplot",
    "href": "posts/ggplot2/index.html#economist-scatterplot",
    "title": "ggplot2 for advanced visalization",
    "section": "Economist Scatterplot",
    "text": "Economist Scatterplot\nUsing following dataset we can reproduce this figure:\n\n\n\nThe Economist plot\n\n\nOriginal code by Raukr. Main components:\np &lt;- ggplot(ec,aes(x=CPI,y=HDI,color=Region))+\n      geom_smooth(aes(fill=\"red\"),method=\"lm\",formula=y~poly(x,2),se=F,color=\"red\",size=0.6)+\n      geom_point(shape=21,size=3,stroke=0.8,fill=\"white\")\np\n\n\n\nplot1\n\n\nText and labels:\nlibrary(ggrepel)\nlibrary(extrafont)\nfont_import(pattern=\"Gidole\",prompt=FALSE)\n\nlabels &lt;- c(\"Congo\",\"Afghanistan\",\"Sudan\",\"Myanmar\",\"Iraq\",\"Venezuela\",\"Russia\",\"Argentina\",\"Brazil\",\"Italy\",\"South Africa\",\"Cape Verde\",\"Bhutan\",\"Botswana\",\"Britian\",\"New Zealand\",\"Greece\",\"China\",\"India\",\"Rwanda\",\"Spain\",\"France\",\"United States\",\"Japan\",\"Norway\",\"Singapore\",\"Barbados\",\"Germany\")\n\np &lt;- p+geom_text_repel(data=subset(ec,Country %in% labels),aes(label=Country),\n                       color=\"black\",box.padding=unit(1,'lines'),segment.size=0.25,\n                       size=3,family=\"Gidole\")\np\n\n\n\nplot2\n\n\nAxes and scale colors:\np &lt;- p+scale_x_continuous(name=\"Corruption Perceptions Index, 2011 (10=least corrupt)\",\n                          breaks=1:10,limits=c(1,10))+\n      scale_y_continuous(name=\"Human Development Index, 2011 (1=best)\",\n                         breaks=seq(from=0,to=1,by=0.1),limits=c(0.2,1))\np &lt;- p+scale_color_manual(values=c(\"#23576E\",\"#099FDB\",\"#29B00E\", \"#208F84\",\"#F55840\",\"#924F3E\"))+\n       scale_fill_manual(name=\"trend\",values=\"red\",labels=expression(paste(R^2,\"=52%\")))\np\n\n\n\nplot3\n\n\nTitle and theme:\np &lt;- p+labs(title=\"Corruption and human development\",\n            caption=\"Sources: Transparency International; UN Human Development Report\")\np &lt;- p+guides(color=guide_legend(nrow=1))+\n       theme_bw(base_family=\"Gidole\")+\n       theme(legend.position=\"top\")\np\n\n\n\nplot4\n\n\n\n\n\n\n\n\nTip\n\n\n\nSometimes it’s faster and more convenient to post-process vector images after saving them from ggplot2 than to set all the parameters within the R code. However, you can save and reuse “standard” themes by keeping them in a separate R script file.\n\n\nThere are many R packages built on top of ggplot2 that simplify visualization tasks while inheriting its core logic. You can find some of them listed here"
  },
  {
    "objectID": "posts/nf_core/index.html",
    "href": "posts/nf_core/index.html",
    "title": "Standartised nf-core pipelines",
    "section": "",
    "text": "If you have a common task for NGS data processing - check this out.\nIn most cases with common data types and analyses, you don’t need to create a workflow from scratch. The Nextflow community has created many pipelines that are highly reproducible, versioned, and utilize containers or Conda environments:\n\n\n\nnf-core pipelines\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can ensure reproducibility by using a specific version of the pipeline. While there is sometimes limited flexibility in the tool parameters, you can address this by editing specific modules of the pipelines locally.\n\n\nTo configure the pipeline, you should consult the webpage of the corresponding workflow. However, in general, a few key items need to be set up before starting:\n\nPipeline and version\nConfiguration profile for your executor\nWorkflow parameters (including input tables, etc.)\n\n\n\n\n\n\n\nImportant\n\n\n\nThese pipelines are the result of countless hours of open-source work and collaboration, so always remember to cite them properly.\n\n\nThere are many ways to learn more about Nextflow and the community:\n\nSlack\nTraining\nSequera AI"
  }
]